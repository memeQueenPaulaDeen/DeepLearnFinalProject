{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/memeQueenPaulaDeen/DeepLearnFinalProject/blob/master/_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmvODeNJKfZz"
      },
      "source": [
        "import numpy as np\n",
        "from pickle import dump\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/final_project/data'\n",
        "\n",
        "train_x = []\n",
        "train_y = []\n",
        "test_x = []\n",
        "test_y = []\n",
        "for file in listdir(data_dir+'/train'):\n",
        "  image = load_img(filename, target_size=(224, 224))\n",
        "  if 'out' in file:\n",
        "    train_y.append(image)\n",
        "  else:\n",
        "    train_x.appened(image)\n",
        "\n",
        "for file in listdir(data_dir+'/test'):\n",
        "  image = load_img(filename, target_size=(224, 224))\n",
        "  if 'out' in file:\n",
        "    test_y.append(image)\n",
        "  else:\n",
        "    test_x.appened(image)\n",
        "\n",
        "# normalize image pixel values to [0-1] - divide by max value\n",
        "train_x = train_x.astype('float32')/255.0\n",
        "test_x = test_x.astype('float32')/255.0\n",
        "\n",
        "dump(train_x, open(data_dir+'/train_x.pkl', 'wb'))\n",
        "dump(train_y, open(data_dir+'/train_y.pkl', 'wb'))\n",
        "dump(test_x, open(data_dir+'/test_x.pkl', 'wb'))\n",
        "dump(test_y, open(data_dir+'/test_y.pkl', 'wb'))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yk-J10cHtAP"
      },
      "source": [
        "base_dir = '/content/drive/MyDrive/final_project'\n",
        "base_dir_out ='/content/drive/MyDrive/final_project/base' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YbHfDJZdWoR"
      },
      "source": [
        "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Add\n",
        "from keras.layers import Activation, Dropout, AveragePooling2D, Flatten, concatenate, UpSampling2D\n",
        "from keras.models import Model, load_model\n",
        "from keras.optimizers import SGD, Adam, Adagrad, RMSprop, schedules\n",
        "from keras.datasets import cifar10\n",
        "from keras.datasets import cifar100\n",
        "from keras.utils import to_categorical, plot_model\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "from pickle import load, dump\n",
        "\n",
        "def gen_model(input_shape, num_classes):\n",
        "  #U-Net implementation \n",
        "  #https://github.com/zhixuhao/unet/blob/master/model.py\n",
        "  img_input = Input(img_shape)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(img_input)\n",
        "  conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "  conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  \n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "  conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  \n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "  conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "  drop4 = Dropout(0.5)(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "  conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "  drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "  up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "  merge6 = concatenate([drop4,up6], axis = 3)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "  conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "\n",
        "  up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "  merge7 = concatenate([conv3,up7], axis = 3)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "  conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "\n",
        "  up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "  merge8 = concatenate([conv2,up8], axis = 3)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "  conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "\n",
        "  up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "  merge9 = concatenate([conv1,up9], axis = 3)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "  conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "  conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "  conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
        "\n",
        "  # Cost Map extension\n",
        "  conv11 = Conv2D(num_classes, 3, activation = 'relu', padding = 'same', kerenel_initializer = 'he_normal')(conv10)\n",
        "  conv11 = Conv2D(num_classes, 3, activation = 'relu', padding = 'same', kerenel_initializer = 'he_normal')(conv10)\n",
        "  conv11 = Conv2D(1, 3, activation = 'sigmoid', padding = 'same', kerenel_initializer = 'he_normal')(conv10)\n",
        "  \n",
        "  model = Model(input = inputs, output = conv10)\n",
        "  return model\n",
        "\n",
        "\n",
        "def run_model(base_dir, run_params, model_params):\n",
        "  ########## Program Variables ##########\n",
        "  num_epochs, batch_size, optimizer = run_params\n",
        "  input_shape, num_classes = model_params\n",
        "\n",
        "  ########## Data Loading ##########\n",
        "  train_x = load(open(base_dir+'/data/train_x.pkl', 'rb'))\n",
        "  train_y = load(open(base_dir+'/data/train_y.pkl', 'rb'))\n",
        "  test_x = load(open(base_dir+'/data/test_x.pkl', 'rb'))\n",
        "  test_y = load(open(base_dir+'/data/test_y.pkl', 'rb'))\n",
        "\n",
        "  ########### Generating and Training Model #########\n",
        "  model = gen_model(input_shape, num_classes)\n",
        "\n",
        "  model.compile(optimizer = optimizer, loss = 'mse', metrics = ['accuracy'])\n",
        "\n",
        "  history = model.fit( train_x, train_y, \\\n",
        "            epochs = num_epochs, \\\n",
        "            batch_size = batch_size, \\\n",
        "            validation_data = (test_x, test_y)))\n",
        "\n",
        "  return history, model\n",
        "\n",
        "###########################################\n",
        "\n",
        "num_epochs = 100\n",
        "batch_size = 128\n",
        "optimizer = Adam(lr=1e-4)\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 10\n",
        "\n",
        "run_params = (num_epochs, batch_size, optimizer)\n",
        "model_params = (input_shape, num_classes)\n",
        "\n",
        "history, model = run_model(run_params, model_params)\n",
        "\n",
        "model.save(base_dir_out+'/model.h5')\n",
        "dump(history.history, open(base_dir_out+'/history.pkl', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjdWXnKRxNju"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model \n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model, load_model\n",
        "from pickle import load\n",
        "\n",
        "def show_history(history):\n",
        "  plt.figure(1)\n",
        "  # plot loss\n",
        "  plt.title('Cross Entropy Loss')\n",
        "  plt.plot(history['loss'], color='blue', label='train')\n",
        "  plt.plot(history['val_loss'], color='orange', label='test')\n",
        "  # plot accuracy\n",
        "  plt.figure(2)\n",
        "  plt.title('Classification Accuracy')\n",
        "  plt.plot(history['accuracy'], color='blue', label='train')\n",
        "  plt.plot(history['val_accuracy'], color='orange', label='test')\n",
        "\n",
        "  plt.show()\n",
        "  print(history['val_accuracy'][-1])\n",
        "###########################################################\n",
        "\n",
        "history = load(open(base_dir_out+'history.pkl', 'rb'))\n",
        "show_history(history)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}